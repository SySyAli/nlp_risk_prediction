{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syeda\\OneDrive\\Documents\\American Bureau of Shipping\\projects\\nlp_risk_prediction\\nlp_env\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "c:\\Users\\syeda\\OneDrive\\Documents\\American Bureau of Shipping\\projects\\nlp_risk_prediction\\nlp_env\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:329: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Import the excel spreadsheets in the data folder\n",
    "installer_df = pd.read_excel('../data/Installer.xlsx')\n",
    "involver_df = pd.read_excel('../data/Involver.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to merge using a subset of key columns\n",
    "merge_on_columns = ['Site', 'Vessel_Name', 'Wo_No']\n",
    "\n",
    "df = pd.concat([installer_df, involver_df], axis=0)\n",
    "\n",
    "# feature_columns = ['Object', 'Group', 'Symptom', 'Error_Cause', 'Cause_Details', 'Error_Class', 'Discovery', 'Completion_Note', 'Action_Taken', 'Work_Description', 'Directive']\n",
    "feature_columns = ['Object', 'Group', 'Object_Type','Completion_Note', 'Work_Description', 'Directive']\n",
    "# TODO: Change this to ESB1\n",
    "target_column = 'EBS1'\n",
    "\n",
    "# Filter the dataframe for the selected columns\n",
    "df = df[feature_columns + [target_column]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'),\n",
       " array([24,  2, 13,  5, 25, 12, 10,  4, 20,  8, 21, 28, 29,  9, 15, 17,  1,\n",
       "         3, 18, 19, 26, 11,  0,  7, 22, 23, 14,  6, 27, 16]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the target column to ids \n",
    "# Encode the target column\n",
    "label_encoder = LabelEncoder()\n",
    "df[target_column] = label_encoder.fit_transform(df[target_column].astype(str))\n",
    "df[target_column].dtype, df[target_column].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.18784468\n",
      "Iteration 2, loss = 3.06258272\n",
      "Iteration 3, loss = 2.91513980\n",
      "Iteration 4, loss = 2.77043023\n",
      "Iteration 5, loss = 2.63224226\n",
      "Iteration 6, loss = 2.50058122\n",
      "Iteration 7, loss = 2.37537254\n",
      "Iteration 8, loss = 2.25716300\n",
      "Iteration 9, loss = 2.14442676\n",
      "Iteration 10, loss = 2.03807581\n",
      "Iteration 11, loss = 1.93798347\n",
      "Iteration 12, loss = 1.84414812\n",
      "Iteration 13, loss = 1.75618562\n",
      "Iteration 14, loss = 1.67373911\n",
      "Iteration 15, loss = 1.59599504\n",
      "Iteration 16, loss = 1.52273787\n",
      "Iteration 17, loss = 1.45440845\n",
      "Iteration 18, loss = 1.39030871\n",
      "Iteration 19, loss = 1.32989710\n",
      "Iteration 20, loss = 1.27303068\n",
      "Iteration 21, loss = 1.21978530\n",
      "Iteration 22, loss = 1.16971891\n",
      "Iteration 23, loss = 1.12281823\n",
      "Iteration 24, loss = 1.07899762\n",
      "Iteration 25, loss = 1.03755251\n",
      "Iteration 26, loss = 0.99872663\n",
      "Iteration 27, loss = 0.96192890\n",
      "Iteration 28, loss = 0.92712676\n",
      "Iteration 29, loss = 0.89430731\n",
      "Iteration 30, loss = 0.86304571\n",
      "Iteration 31, loss = 0.83385171\n",
      "Iteration 32, loss = 0.80629180\n",
      "Iteration 33, loss = 0.78003721\n",
      "Iteration 34, loss = 0.75542255\n",
      "Iteration 35, loss = 0.73205051\n",
      "Iteration 36, loss = 0.70986751\n",
      "Iteration 37, loss = 0.68884484\n",
      "Iteration 38, loss = 0.66899468\n",
      "Iteration 39, loss = 0.65030336\n",
      "Iteration 40, loss = 0.63255600\n",
      "Iteration 41, loss = 0.61545944\n",
      "Iteration 42, loss = 0.59905358\n",
      "Iteration 43, loss = 0.58375349\n",
      "Iteration 44, loss = 0.56909750\n",
      "Iteration 45, loss = 0.55513362\n",
      "Iteration 46, loss = 0.54175110\n",
      "Iteration 47, loss = 0.52914465\n",
      "Iteration 48, loss = 0.51695870\n",
      "Iteration 49, loss = 0.50546110\n",
      "Iteration 50, loss = 0.49439634\n",
      "Iteration 51, loss = 0.48376608\n",
      "Iteration 52, loss = 0.47372860\n",
      "Iteration 53, loss = 0.46407742\n",
      "Iteration 54, loss = 0.45478906\n",
      "Iteration 55, loss = 0.44582062\n",
      "Iteration 56, loss = 0.43733200\n",
      "Iteration 57, loss = 0.42917069\n",
      "Iteration 58, loss = 0.42132583\n",
      "Iteration 59, loss = 0.41371585\n",
      "Iteration 60, loss = 0.40640029\n",
      "Iteration 61, loss = 0.39935297\n",
      "Iteration 62, loss = 0.39254693\n",
      "Iteration 63, loss = 0.38607826\n",
      "Iteration 64, loss = 0.37983909\n",
      "Iteration 65, loss = 0.37379837\n",
      "Iteration 66, loss = 0.36802957\n",
      "Iteration 67, loss = 0.36216404\n",
      "Iteration 68, loss = 0.35667665\n",
      "Iteration 69, loss = 0.35137625\n",
      "Iteration 70, loss = 0.34627098\n",
      "Iteration 71, loss = 0.34127548\n",
      "Iteration 72, loss = 0.33657544\n",
      "Iteration 73, loss = 0.33191176\n",
      "Iteration 74, loss = 0.32740418\n",
      "Iteration 75, loss = 0.32306260\n",
      "Iteration 76, loss = 0.31878589\n",
      "Iteration 77, loss = 0.31465604\n",
      "Iteration 78, loss = 0.31069535\n",
      "Iteration 79, loss = 0.30680015\n",
      "Iteration 80, loss = 0.30302096\n",
      "Iteration 81, loss = 0.29921632\n",
      "Iteration 82, loss = 0.29559762\n",
      "Iteration 83, loss = 0.29217190\n",
      "Iteration 84, loss = 0.28882334\n",
      "Iteration 85, loss = 0.28529683\n",
      "Iteration 86, loss = 0.28207071\n",
      "Iteration 87, loss = 0.27887266\n",
      "Iteration 88, loss = 0.27575910\n",
      "Iteration 89, loss = 0.27280329\n",
      "Iteration 90, loss = 0.26984408\n",
      "Iteration 91, loss = 0.26694722\n",
      "Iteration 92, loss = 0.26409014\n",
      "Iteration 93, loss = 0.26134127\n",
      "Iteration 94, loss = 0.25868511\n",
      "Iteration 95, loss = 0.25609856\n",
      "Iteration 96, loss = 0.25357593\n",
      "Iteration 97, loss = 0.25104752\n",
      "Iteration 98, loss = 0.24861228\n",
      "Iteration 99, loss = 0.24624733\n",
      "Iteration 100, loss = 0.24381402\n",
      "Iteration 101, loss = 0.24149364\n",
      "Iteration 102, loss = 0.23919301\n",
      "Iteration 103, loss = 0.23696675\n",
      "Iteration 104, loss = 0.23481994\n",
      "Iteration 105, loss = 0.23271386\n",
      "Iteration 106, loss = 0.23056597\n",
      "Iteration 107, loss = 0.22854287\n",
      "Iteration 108, loss = 0.22647180\n",
      "Iteration 109, loss = 0.22451074\n",
      "Iteration 110, loss = 0.22254485\n",
      "Iteration 111, loss = 0.22061458\n",
      "Iteration 112, loss = 0.21877888\n",
      "Iteration 113, loss = 0.21692870\n",
      "Iteration 114, loss = 0.21509123\n",
      "Iteration 115, loss = 0.21331390\n",
      "Iteration 116, loss = 0.21155440\n",
      "Iteration 117, loss = 0.20985060\n",
      "Iteration 118, loss = 0.20815334\n",
      "Iteration 119, loss = 0.20639948\n",
      "Iteration 120, loss = 0.20473372\n",
      "Iteration 121, loss = 0.20312749\n",
      "Iteration 122, loss = 0.20154409\n",
      "Iteration 123, loss = 0.19996002\n",
      "Iteration 124, loss = 0.19843250\n",
      "Iteration 125, loss = 0.19690650\n",
      "Iteration 126, loss = 0.19543021\n",
      "Iteration 127, loss = 0.19397090\n",
      "Iteration 128, loss = 0.19246796\n",
      "Iteration 129, loss = 0.19107222\n",
      "Iteration 130, loss = 0.18965625\n",
      "Iteration 131, loss = 0.18822089\n",
      "Iteration 132, loss = 0.18686606\n",
      "Iteration 133, loss = 0.18550504\n",
      "Iteration 134, loss = 0.18420030\n",
      "Iteration 135, loss = 0.18286663\n",
      "Iteration 136, loss = 0.18155816\n",
      "Iteration 137, loss = 0.18027398\n",
      "Iteration 138, loss = 0.17901137\n",
      "Iteration 139, loss = 0.17774032\n",
      "Iteration 140, loss = 0.17649892\n",
      "Iteration 141, loss = 0.17527465\n",
      "Iteration 142, loss = 0.17407111\n",
      "Iteration 143, loss = 0.17286106\n",
      "Iteration 144, loss = 0.17167848\n",
      "Iteration 145, loss = 0.17050014\n",
      "Iteration 146, loss = 0.16937135\n",
      "Iteration 147, loss = 0.16823073\n",
      "Iteration 148, loss = 0.16711511\n",
      "Iteration 149, loss = 0.16602927\n",
      "Iteration 150, loss = 0.16490440\n",
      "Iteration 151, loss = 0.16384472\n",
      "Iteration 152, loss = 0.16280201\n",
      "Iteration 153, loss = 0.16175550\n",
      "Iteration 154, loss = 0.16072876\n",
      "Iteration 155, loss = 0.15969758\n",
      "Iteration 156, loss = 0.15867701\n",
      "Iteration 157, loss = 0.15769019\n",
      "Iteration 158, loss = 0.15668892\n",
      "Iteration 159, loss = 0.15562840\n",
      "Iteration 160, loss = 0.15465409\n",
      "Iteration 161, loss = 0.15369243\n",
      "Iteration 162, loss = 0.15274563\n",
      "Iteration 163, loss = 0.15178886\n",
      "Iteration 164, loss = 0.15084195\n",
      "Iteration 165, loss = 0.14988116\n",
      "Iteration 166, loss = 0.14894071\n",
      "Iteration 167, loss = 0.14804955\n",
      "Iteration 168, loss = 0.14716571\n",
      "Iteration 169, loss = 0.14630667\n",
      "Iteration 170, loss = 0.14538619\n",
      "Iteration 171, loss = 0.14450970\n",
      "Iteration 172, loss = 0.14366328\n",
      "Iteration 173, loss = 0.14281522\n",
      "Iteration 174, loss = 0.14198121\n",
      "Iteration 175, loss = 0.14116442\n",
      "Iteration 176, loss = 0.14033205\n",
      "Iteration 177, loss = 0.13954608\n",
      "Iteration 178, loss = 0.13874765\n",
      "Iteration 179, loss = 0.13795721\n",
      "Iteration 180, loss = 0.13716019\n",
      "Iteration 181, loss = 0.13637797\n",
      "Iteration 182, loss = 0.13560935\n",
      "Iteration 183, loss = 0.13487397\n",
      "Iteration 184, loss = 0.13411055\n",
      "Iteration 185, loss = 0.13336257\n",
      "Iteration 186, loss = 0.13263745\n",
      "Iteration 187, loss = 0.13191983\n",
      "Iteration 188, loss = 0.13120357\n",
      "Iteration 189, loss = 0.13045004\n",
      "Iteration 190, loss = 0.12976476\n",
      "Iteration 191, loss = 0.12909789\n",
      "Iteration 192, loss = 0.12836762\n",
      "Iteration 193, loss = 0.12769723\n",
      "Iteration 194, loss = 0.12697867\n",
      "Iteration 195, loss = 0.12629761\n",
      "Iteration 196, loss = 0.12564348\n",
      "Iteration 197, loss = 0.12498294\n",
      "Iteration 198, loss = 0.12431328\n",
      "Iteration 199, loss = 0.12364209\n",
      "Iteration 200, loss = 0.12299521\n",
      "Iteration 201, loss = 0.12234862\n",
      "Iteration 202, loss = 0.12171878\n",
      "Iteration 203, loss = 0.12108416\n",
      "Iteration 204, loss = 0.12046966\n",
      "Iteration 205, loss = 0.11983758\n",
      "Iteration 206, loss = 0.11924454\n",
      "Iteration 207, loss = 0.11859938\n",
      "Iteration 208, loss = 0.11800144\n",
      "Iteration 209, loss = 0.11742037\n",
      "Iteration 210, loss = 0.11680430\n",
      "Iteration 211, loss = 0.11622120\n",
      "Iteration 212, loss = 0.11562362\n",
      "Iteration 213, loss = 0.11507996\n",
      "Iteration 214, loss = 0.11450764\n",
      "Iteration 215, loss = 0.11393849\n",
      "Iteration 216, loss = 0.11336253\n",
      "Iteration 217, loss = 0.11281419\n",
      "Iteration 218, loss = 0.11228305\n",
      "Iteration 219, loss = 0.11171092\n",
      "Iteration 220, loss = 0.11118616\n",
      "Iteration 221, loss = 0.11062267\n",
      "Iteration 222, loss = 0.11011877\n",
      "Iteration 223, loss = 0.10958076\n",
      "Iteration 224, loss = 0.10905298\n",
      "Iteration 225, loss = 0.10852255\n",
      "Iteration 226, loss = 0.10800181\n",
      "Iteration 227, loss = 0.10748873\n",
      "Iteration 228, loss = 0.10697442\n",
      "Iteration 229, loss = 0.10645774\n",
      "Iteration 230, loss = 0.10593987\n",
      "Iteration 231, loss = 0.10544640\n",
      "Iteration 232, loss = 0.10494331\n",
      "Iteration 233, loss = 0.10445950\n",
      "Iteration 234, loss = 0.10398716\n",
      "Iteration 235, loss = 0.10347341\n",
      "Iteration 236, loss = 0.10299432\n",
      "Iteration 237, loss = 0.10251165\n",
      "Iteration 238, loss = 0.10204405\n",
      "Iteration 239, loss = 0.10156587\n",
      "Iteration 240, loss = 0.10108793\n",
      "Iteration 241, loss = 0.10059160\n",
      "Iteration 242, loss = 0.10014596\n",
      "Iteration 243, loss = 0.09970392\n",
      "Iteration 244, loss = 0.09924498\n",
      "Iteration 245, loss = 0.09880113\n",
      "Iteration 246, loss = 0.09834522\n",
      "Iteration 247, loss = 0.09792103\n",
      "Iteration 248, loss = 0.09744620\n",
      "Iteration 249, loss = 0.09700296\n",
      "Iteration 250, loss = 0.09656984\n",
      "Iteration 251, loss = 0.09615871\n",
      "Iteration 252, loss = 0.09571664\n",
      "Iteration 253, loss = 0.09530840\n",
      "Iteration 254, loss = 0.09491248\n",
      "Iteration 255, loss = 0.09448334\n",
      "Iteration 256, loss = 0.09404391\n",
      "Iteration 257, loss = 0.09364599\n",
      "Iteration 258, loss = 0.09325115\n",
      "Iteration 259, loss = 0.09283183\n",
      "Iteration 260, loss = 0.09243620\n",
      "Iteration 261, loss = 0.09207185\n",
      "Iteration 262, loss = 0.09165279\n",
      "Iteration 263, loss = 0.09125548\n",
      "Iteration 264, loss = 0.09086451\n",
      "Iteration 265, loss = 0.09046362\n",
      "Iteration 266, loss = 0.09010309\n",
      "Iteration 267, loss = 0.08973927\n",
      "Iteration 268, loss = 0.08935048\n",
      "Iteration 269, loss = 0.08898349\n",
      "Iteration 270, loss = 0.08860753\n",
      "Iteration 271, loss = 0.08824158\n",
      "Iteration 272, loss = 0.08788871\n",
      "Iteration 273, loss = 0.08751578\n",
      "Iteration 274, loss = 0.08715846\n",
      "Iteration 275, loss = 0.08679529\n",
      "Iteration 276, loss = 0.08643191\n",
      "Iteration 277, loss = 0.08606318\n",
      "Iteration 278, loss = 0.08571501\n",
      "Iteration 279, loss = 0.08537552\n",
      "Iteration 280, loss = 0.08504479\n",
      "Iteration 281, loss = 0.08469871\n",
      "Iteration 282, loss = 0.08436255\n",
      "Iteration 283, loss = 0.08401989\n",
      "Iteration 284, loss = 0.08368988\n",
      "Iteration 285, loss = 0.08335741\n",
      "Iteration 286, loss = 0.08301188\n",
      "Iteration 287, loss = 0.08269146\n",
      "Iteration 288, loss = 0.08237757\n",
      "Iteration 289, loss = 0.08204038\n",
      "Iteration 290, loss = 0.08172936\n",
      "Iteration 291, loss = 0.08141343\n",
      "Iteration 292, loss = 0.08110785\n",
      "Iteration 293, loss = 0.08077820\n",
      "Iteration 294, loss = 0.08046474\n",
      "Iteration 295, loss = 0.08014912\n",
      "Iteration 296, loss = 0.07982650\n",
      "Iteration 297, loss = 0.07952672\n",
      "Iteration 298, loss = 0.07921314\n",
      "Iteration 299, loss = 0.07894587\n",
      "Iteration 300, loss = 0.07862046\n",
      "Iteration 301, loss = 0.07828256\n",
      "Iteration 302, loss = 0.07797776\n",
      "Iteration 303, loss = 0.07770856\n",
      "Iteration 304, loss = 0.07739551\n",
      "Iteration 305, loss = 0.07709316\n",
      "Iteration 306, loss = 0.07680765\n",
      "Iteration 307, loss = 0.07652286\n",
      "Iteration 308, loss = 0.07623291\n",
      "Iteration 309, loss = 0.07596349\n",
      "Iteration 310, loss = 0.07567887\n",
      "Iteration 311, loss = 0.07540431\n",
      "Iteration 312, loss = 0.07513084\n",
      "Iteration 313, loss = 0.07485316\n",
      "Iteration 314, loss = 0.07457543\n",
      "Iteration 315, loss = 0.07432718\n",
      "Iteration 316, loss = 0.07401098\n",
      "Iteration 317, loss = 0.07372615\n",
      "Iteration 318, loss = 0.07346257\n",
      "Iteration 319, loss = 0.07319058\n",
      "Iteration 320, loss = 0.07292600\n",
      "Iteration 321, loss = 0.07267118\n",
      "Iteration 322, loss = 0.07240680\n",
      "Iteration 323, loss = 0.07216012\n",
      "Iteration 324, loss = 0.07187972\n",
      "Iteration 325, loss = 0.07162971\n",
      "Iteration 326, loss = 0.07136891\n",
      "Iteration 327, loss = 0.07113277\n",
      "Iteration 328, loss = 0.07086964\n",
      "Iteration 329, loss = 0.07063363\n",
      "Iteration 330, loss = 0.07035716\n",
      "Iteration 331, loss = 0.07010814\n",
      "Iteration 332, loss = 0.06987900\n",
      "Iteration 333, loss = 0.06962519\n",
      "Iteration 334, loss = 0.06936801\n",
      "Iteration 335, loss = 0.06912503\n",
      "Iteration 336, loss = 0.06889433\n",
      "Iteration 337, loss = 0.06865553\n",
      "Iteration 338, loss = 0.06839013\n",
      "Iteration 339, loss = 0.06815573\n",
      "Iteration 340, loss = 0.06792741\n",
      "Iteration 341, loss = 0.06769368\n",
      "Iteration 342, loss = 0.06746583\n",
      "Iteration 343, loss = 0.06722589\n",
      "Iteration 344, loss = 0.06699577\n",
      "Iteration 345, loss = 0.06676250\n",
      "Iteration 346, loss = 0.06653791\n",
      "Iteration 347, loss = 0.06631601\n",
      "Iteration 348, loss = 0.06607937\n",
      "Iteration 349, loss = 0.06585747\n",
      "Iteration 350, loss = 0.06563876\n",
      "Iteration 351, loss = 0.06538505\n",
      "Iteration 352, loss = 0.06516981\n",
      "Iteration 353, loss = 0.06494439\n",
      "Iteration 354, loss = 0.06473443\n",
      "Iteration 355, loss = 0.06451247\n",
      "Iteration 356, loss = 0.06429566\n",
      "Iteration 357, loss = 0.06409229\n",
      "Iteration 358, loss = 0.06387285\n",
      "Iteration 359, loss = 0.06366742\n",
      "Iteration 360, loss = 0.06346654\n",
      "Iteration 361, loss = 0.06327163\n",
      "Iteration 362, loss = 0.06303700\n",
      "Iteration 363, loss = 0.06283976\n",
      "Iteration 364, loss = 0.06264587\n",
      "Iteration 365, loss = 0.06243209\n",
      "Iteration 366, loss = 0.06223780\n",
      "Iteration 367, loss = 0.06203499\n",
      "Iteration 368, loss = 0.06183607\n",
      "Iteration 369, loss = 0.06165810\n",
      "Iteration 370, loss = 0.06144638\n",
      "Iteration 371, loss = 0.06126393\n",
      "Iteration 372, loss = 0.06109315\n",
      "Iteration 373, loss = 0.06088398\n",
      "Iteration 374, loss = 0.06069696\n",
      "Iteration 375, loss = 0.06050790\n",
      "Iteration 376, loss = 0.06031555\n",
      "Iteration 377, loss = 0.06013221\n",
      "Iteration 378, loss = 0.05994932\n",
      "Iteration 379, loss = 0.05975509\n",
      "Iteration 380, loss = 0.05958726\n",
      "Iteration 381, loss = 0.05938543\n",
      "Iteration 382, loss = 0.05920990\n",
      "Iteration 383, loss = 0.05902180\n",
      "Iteration 384, loss = 0.05884896\n",
      "Iteration 385, loss = 0.05867877\n",
      "Iteration 386, loss = 0.05848283\n",
      "Iteration 387, loss = 0.05830629\n",
      "Iteration 388, loss = 0.05812874\n",
      "Iteration 389, loss = 0.05794806\n",
      "Iteration 390, loss = 0.05776269\n",
      "Iteration 391, loss = 0.05758710\n",
      "Iteration 392, loss = 0.05742732\n",
      "Iteration 393, loss = 0.05725788\n",
      "Iteration 394, loss = 0.05707705\n",
      "Iteration 395, loss = 0.05692131\n",
      "Iteration 396, loss = 0.05674599\n",
      "Iteration 397, loss = 0.05657825\n",
      "Iteration 398, loss = 0.05640278\n",
      "Iteration 399, loss = 0.05624258\n",
      "Iteration 400, loss = 0.05608739\n",
      "Iteration 401, loss = 0.05591546\n",
      "Iteration 402, loss = 0.05575277\n",
      "Iteration 403, loss = 0.05557506\n",
      "Iteration 404, loss = 0.05541919\n",
      "Iteration 405, loss = 0.05525579\n",
      "Iteration 406, loss = 0.05508243\n",
      "Iteration 407, loss = 0.05492210\n",
      "Iteration 408, loss = 0.05476766\n",
      "Iteration 409, loss = 0.05460906\n",
      "Iteration 410, loss = 0.05445110\n",
      "Iteration 411, loss = 0.05432185\n",
      "Iteration 412, loss = 0.05414936\n",
      "Iteration 413, loss = 0.05401227\n",
      "Iteration 414, loss = 0.05383787\n",
      "Iteration 415, loss = 0.05367598\n",
      "Iteration 416, loss = 0.05353016\n",
      "Iteration 417, loss = 0.05337796\n",
      "Iteration 418, loss = 0.05322639\n",
      "Iteration 419, loss = 0.05307959\n",
      "Iteration 420, loss = 0.05293331\n",
      "Iteration 421, loss = 0.05278835\n",
      "Iteration 422, loss = 0.05264488\n",
      "Iteration 423, loss = 0.05248804\n",
      "Iteration 424, loss = 0.05233432\n",
      "Iteration 425, loss = 0.05219869\n",
      "Iteration 426, loss = 0.05204923\n",
      "Iteration 427, loss = 0.05191252\n",
      "Iteration 428, loss = 0.05177075\n",
      "Iteration 429, loss = 0.05164120\n",
      "Iteration 430, loss = 0.05149607\n",
      "Iteration 431, loss = 0.05135938\n",
      "Iteration 432, loss = 0.05120875\n",
      "Iteration 433, loss = 0.05107088\n",
      "Iteration 434, loss = 0.05093647\n",
      "Iteration 435, loss = 0.05080481\n",
      "Iteration 436, loss = 0.05065035\n",
      "Iteration 437, loss = 0.05054401\n",
      "Iteration 438, loss = 0.05040600\n",
      "Iteration 439, loss = 0.05026979\n",
      "Iteration 440, loss = 0.05012364\n",
      "Iteration 441, loss = 0.04999369\n",
      "Iteration 442, loss = 0.04985188\n",
      "Iteration 443, loss = 0.04972025\n",
      "Iteration 444, loss = 0.04959398\n",
      "Iteration 445, loss = 0.04945824\n",
      "Iteration 446, loss = 0.04933195\n",
      "Iteration 447, loss = 0.04920347\n",
      "Iteration 448, loss = 0.04906801\n",
      "Iteration 449, loss = 0.04894246\n",
      "Iteration 450, loss = 0.04880576\n",
      "Iteration 451, loss = 0.04867778\n",
      "Iteration 452, loss = 0.04854772\n",
      "Iteration 453, loss = 0.04843266\n",
      "Iteration 454, loss = 0.04830246\n",
      "Iteration 455, loss = 0.04817601\n",
      "Iteration 456, loss = 0.04807164\n",
      "Iteration 457, loss = 0.04793946\n",
      "Iteration 458, loss = 0.04782388\n",
      "Iteration 459, loss = 0.04770094\n",
      "Iteration 460, loss = 0.04757106\n",
      "Iteration 461, loss = 0.04744631\n",
      "Iteration 462, loss = 0.04732529\n",
      "Iteration 463, loss = 0.04721644\n",
      "Iteration 464, loss = 0.04708595\n",
      "Iteration 465, loss = 0.04696875\n",
      "Iteration 466, loss = 0.04684139\n",
      "Iteration 467, loss = 0.04673091\n",
      "Iteration 468, loss = 0.04660343\n",
      "Iteration 469, loss = 0.04649720\n",
      "Iteration 470, loss = 0.04636939\n",
      "Iteration 471, loss = 0.04625094\n",
      "Iteration 472, loss = 0.04611376\n",
      "Iteration 473, loss = 0.04601474\n",
      "Iteration 474, loss = 0.04589850\n",
      "Iteration 475, loss = 0.04579080\n",
      "Iteration 476, loss = 0.04566791\n",
      "Iteration 477, loss = 0.04556007\n",
      "Iteration 478, loss = 0.04544780\n",
      "Iteration 479, loss = 0.04533371\n",
      "Iteration 480, loss = 0.04523609\n",
      "Iteration 481, loss = 0.04511488\n",
      "Iteration 482, loss = 0.04502020\n",
      "Iteration 483, loss = 0.04489313\n",
      "Iteration 484, loss = 0.04478571\n",
      "Iteration 485, loss = 0.04467421\n",
      "Iteration 486, loss = 0.04457640\n",
      "Iteration 487, loss = 0.04446272\n",
      "Iteration 488, loss = 0.04435927\n",
      "Iteration 489, loss = 0.04425593\n",
      "Iteration 490, loss = 0.04414971\n",
      "Iteration 491, loss = 0.04404474\n",
      "Iteration 492, loss = 0.04397477\n",
      "Iteration 493, loss = 0.04383992\n",
      "Iteration 494, loss = 0.04373001\n",
      "Iteration 495, loss = 0.04363745\n",
      "Iteration 496, loss = 0.04351511\n",
      "Iteration 497, loss = 0.04343981\n",
      "Iteration 498, loss = 0.04333492\n",
      "Iteration 499, loss = 0.04321689\n",
      "Iteration 500, loss = 0.04311883\n",
      "Iteration 501, loss = 0.04301995\n",
      "Iteration 502, loss = 0.04292127\n",
      "Iteration 503, loss = 0.04281647\n",
      "Iteration 504, loss = 0.04271755\n",
      "Iteration 505, loss = 0.04261569\n",
      "Iteration 506, loss = 0.04253454\n",
      "Iteration 507, loss = 0.04241953\n",
      "Iteration 508, loss = 0.04232184\n",
      "Iteration 509, loss = 0.04224169\n",
      "Iteration 510, loss = 0.04213760\n",
      "Iteration 511, loss = 0.04203783\n",
      "Iteration 512, loss = 0.04194129\n",
      "Iteration 513, loss = 0.04184461\n",
      "Iteration 514, loss = 0.04175240\n",
      "Iteration 515, loss = 0.04164755\n",
      "Iteration 516, loss = 0.04155809\n",
      "Iteration 517, loss = 0.04144464\n",
      "Iteration 518, loss = 0.04136893\n",
      "Iteration 519, loss = 0.04126285\n",
      "Iteration 520, loss = 0.04115557\n",
      "Iteration 521, loss = 0.04107764\n",
      "Iteration 522, loss = 0.04099020\n",
      "Iteration 523, loss = 0.04087903\n",
      "Iteration 524, loss = 0.04080462\n",
      "Iteration 525, loss = 0.04070601\n",
      "Iteration 526, loss = 0.04062027\n",
      "Iteration 527, loss = 0.04052975\n",
      "Iteration 528, loss = 0.04044935\n",
      "Iteration 529, loss = 0.04037497\n",
      "Iteration 530, loss = 0.04027654\n",
      "Iteration 531, loss = 0.04019188\n",
      "Iteration 532, loss = 0.04010011\n",
      "Iteration 533, loss = 0.04001299\n",
      "Iteration 534, loss = 0.03992365\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000200\n",
      "Iteration 535, loss = 0.03983762\n",
      "Iteration 536, loss = 0.03980557\n",
      "Iteration 537, loss = 0.03978557\n",
      "Iteration 538, loss = 0.03976471\n",
      "Iteration 539, loss = 0.03975157\n",
      "Iteration 540, loss = 0.03973243\n",
      "Iteration 541, loss = 0.03971553\n",
      "Iteration 542, loss = 0.03970352\n",
      "Iteration 543, loss = 0.03967878\n",
      "Iteration 544, loss = 0.03966210\n",
      "Iteration 545, loss = 0.03964565\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000040\n",
      "Iteration 546, loss = 0.03962885\n",
      "Iteration 547, loss = 0.03962347\n",
      "Iteration 548, loss = 0.03961879\n",
      "Iteration 549, loss = 0.03961545\n",
      "Iteration 550, loss = 0.03961245\n",
      "Iteration 551, loss = 0.03960884\n",
      "Iteration 552, loss = 0.03960521\n",
      "Iteration 553, loss = 0.03960166\n",
      "Iteration 554, loss = 0.03959847\n",
      "Iteration 555, loss = 0.03959465\n",
      "Iteration 556, loss = 0.03959134\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000008\n",
      "Iteration 557, loss = 0.03958800\n",
      "Iteration 558, loss = 0.03958682\n",
      "Iteration 559, loss = 0.03958601\n",
      "Iteration 560, loss = 0.03958530\n",
      "Iteration 561, loss = 0.03958460\n",
      "Iteration 562, loss = 0.03958383\n",
      "Iteration 563, loss = 0.03958320\n",
      "Iteration 564, loss = 0.03958248\n",
      "Iteration 565, loss = 0.03958186\n",
      "Iteration 566, loss = 0.03958113\n",
      "Iteration 567, loss = 0.03958042\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000002\n",
      "Iteration 568, loss = 0.03957971\n",
      "Iteration 569, loss = 0.03957948\n",
      "Iteration 570, loss = 0.03957932\n",
      "Iteration 571, loss = 0.03957919\n",
      "Iteration 572, loss = 0.03957906\n",
      "Iteration 573, loss = 0.03957890\n",
      "Iteration 574, loss = 0.03957877\n",
      "Iteration 575, loss = 0.03957861\n",
      "Iteration 576, loss = 0.03957848\n",
      "Iteration 577, loss = 0.03957834\n",
      "Iteration 578, loss = 0.03957821\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 579, loss = 0.03957807\n",
      "Iteration 580, loss = 0.03957802\n",
      "Iteration 581, loss = 0.03957798\n",
      "Iteration 582, loss = 0.03957796\n",
      "Iteration 583, loss = 0.03957793\n",
      "Iteration 584, loss = 0.03957790\n",
      "Iteration 585, loss = 0.03957787\n",
      "Iteration 586, loss = 0.03957784\n",
      "Iteration 587, loss = 0.03957782\n",
      "Iteration 588, loss = 0.03957779\n",
      "Iteration 589, loss = 0.03957776\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;Object&#x27;, TfidfVectorizer(),\n",
       "                                                  &#x27;Object&#x27;),\n",
       "                                                 (&#x27;Group&#x27;, TfidfVectorizer(),\n",
       "                                                  &#x27;Group&#x27;),\n",
       "                                                 (&#x27;Object_Type&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Object_Type&#x27;),\n",
       "                                                 (&#x27;Completion_Note&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Completion_Note&#x27;),\n",
       "                                                 (&#x27;Work_Description&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Work_Description&#x27;),\n",
       "                                                 (&#x27;Directive&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Directive&#x27;)])),\n",
       "                (&#x27;scaler&#x27;, MaxAbsScaler()), (&#x27;pca&#x27;, PCA(n_components=100)),\n",
       "                (&#x27;sampler&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 100),\n",
       "                               learning_rate=&#x27;adaptive&#x27;, max_iter=1200,\n",
       "                               solver=&#x27;sgd&#x27;, verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;Object&#x27;, TfidfVectorizer(),\n",
       "                                                  &#x27;Object&#x27;),\n",
       "                                                 (&#x27;Group&#x27;, TfidfVectorizer(),\n",
       "                                                  &#x27;Group&#x27;),\n",
       "                                                 (&#x27;Object_Type&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Object_Type&#x27;),\n",
       "                                                 (&#x27;Completion_Note&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Completion_Note&#x27;),\n",
       "                                                 (&#x27;Work_Description&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Work_Description&#x27;),\n",
       "                                                 (&#x27;Directive&#x27;,\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  &#x27;Directive&#x27;)])),\n",
       "                (&#x27;scaler&#x27;, MaxAbsScaler()), (&#x27;pca&#x27;, PCA(n_components=100)),\n",
       "                (&#x27;sampler&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 100),\n",
       "                               learning_rate=&#x27;adaptive&#x27;, max_iter=1200,\n",
       "                               solver=&#x27;sgd&#x27;, verbose=True))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;Object&#x27;, TfidfVectorizer(), &#x27;Object&#x27;),\n",
       "                                (&#x27;Group&#x27;, TfidfVectorizer(), &#x27;Group&#x27;),\n",
       "                                (&#x27;Object_Type&#x27;, TfidfVectorizer(),\n",
       "                                 &#x27;Object_Type&#x27;),\n",
       "                                (&#x27;Completion_Note&#x27;, TfidfVectorizer(),\n",
       "                                 &#x27;Completion_Note&#x27;),\n",
       "                                (&#x27;Work_Description&#x27;, TfidfVectorizer(),\n",
       "                                 &#x27;Work_Description&#x27;),\n",
       "                                (&#x27;Directive&#x27;, TfidfVectorizer(), &#x27;Directive&#x27;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Object</label><div class=\"sk-toggleable__content fitted\"><pre>Object</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Group</label><div class=\"sk-toggleable__content fitted\"><pre>Group</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Object_Type</label><div class=\"sk-toggleable__content fitted\"><pre>Object_Type</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Completion_Note</label><div class=\"sk-toggleable__content fitted\"><pre>Completion_Note</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Work_Description</label><div class=\"sk-toggleable__content fitted\"><pre>Work_Description</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">Directive</label><div class=\"sk-toggleable__content fitted\"><pre>Directive</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MaxAbsScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MaxAbsScaler.html\">?<span>Documentation for MaxAbsScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MaxAbsScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=100)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">RandomOverSampler</label><div class=\"sk-toggleable__content fitted\"><pre>RandomOverSampler(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 100),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=1200, solver=&#x27;sgd&#x27;,\n",
       "              verbose=True)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('Object', TfidfVectorizer(),\n",
       "                                                  'Object'),\n",
       "                                                 ('Group', TfidfVectorizer(),\n",
       "                                                  'Group'),\n",
       "                                                 ('Object_Type',\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  'Object_Type'),\n",
       "                                                 ('Completion_Note',\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  'Completion_Note'),\n",
       "                                                 ('Work_Description',\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  'Work_Description'),\n",
       "                                                 ('Directive',\n",
       "                                                  TfidfVectorizer(),\n",
       "                                                  'Directive')])),\n",
       "                ('scaler', MaxAbsScaler()), ('pca', PCA(n_components=100)),\n",
       "                ('sampler', RandomOverSampler(random_state=42)),\n",
       "                ('classifier',\n",
       "                 MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 100),\n",
       "                               learning_rate='adaptive', max_iter=1200,\n",
       "                               solver='sgd', verbose=True))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling rare classes\n",
    "class_counts = df[target_column].value_counts()\n",
    "threshold = 2  # Minimum number of instances required\n",
    "rare_classes = class_counts[class_counts < threshold].index.tolist()\n",
    "df_filtered = df[~df[target_column].isin(rare_classes)]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df_filtered[feature_columns]\n",
    "y = df_filtered[target_column]\n",
    "\n",
    "# Check if the length of X and y are consistent\n",
    "assert len(X) == len(y), \"Mismatch in the number of samples between X and y\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the TF-IDF vectorizer for text columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (col, TfidfVectorizer(), col) for col in feature_columns\n",
    "    ], remainder='drop'\n",
    ")\n",
    "\n",
    "params = {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'max_iter': 1200, 'solver': 'sgd', 'verbose': True}\n",
    "\n",
    "# Create a pipeline with preprocessor, scaler, PCA, and MLPClassifier\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('scaler', MaxAbsScaler()),  # Apply scaler after TF-IDF transformation\n",
    "    ('pca', PCA(n_components=100)),  # Reduce to 100 principal components\n",
    "    ('sampler', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', MLPClassifier(**params))\n",
    "])\n",
    "\n",
    "# Fit the full pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.9090909090909091\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00        22\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       0.93      0.93      0.93        27\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      0.50      0.67         2\n",
      "           9       0.75      1.00      0.86         3\n",
      "          10       1.00      0.67      0.80         3\n",
      "          12       1.00      0.50      0.67         2\n",
      "          13       0.97      0.97      0.97        34\n",
      "          17       0.00      0.00      0.00         2\n",
      "          19       0.50      1.00      0.67         1\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         6\n",
      "          22       0.60      1.00      0.75         3\n",
      "          23       1.00      1.00      1.00         1\n",
      "          25       1.00      1.00      1.00         1\n",
      "          26       1.00      0.33      0.50         3\n",
      "          27       1.00      1.00      1.00         1\n",
      "          28       1.00      1.00      1.00         1\n",
      "          29       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.91       121\n",
      "   macro avg       0.80      0.80      0.77       121\n",
      "weighted avg       0.92      0.91      0.90       121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\syeda\\OneDrive\\Documents\\American Bureau of Shipping\\projects\\nlp_risk_prediction\\nlp_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\syeda\\OneDrive\\Documents\\American Bureau of Shipping\\projects\\nlp_risk_prediction\\nlp_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\syeda\\OneDrive\\Documents\\American Bureau of Shipping\\projects\\nlp_risk_prediction\\nlp_env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot the loss curve\n",
    "classifier = pipeline.named_steps['classifier']\n",
    "plt.plot(classifier.loss_curve_)\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
